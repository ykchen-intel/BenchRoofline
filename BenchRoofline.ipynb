{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9664ab8",
   "metadata": {},
   "source": [
    "## Overall plan\n",
    "# Setup\n",
    "    Variables: the input/output token length, bytes_per_value, types of layers (Done)\n",
    "    Variables: parallelism (P4)\n",
    "    Mixed-precision (P6)\n",
    "# Read config.json (done)\n",
    "# Read hardware specification\n",
    "    Read from Excel spreadsheet (P2)\n",
    "# Breakdown the models into different kernels/tensors\n",
    "    Manually breakdown the GQA models (Done)\n",
    "    MOE models (P3)\n",
    "    Automatic model conversion (P4)\n",
    "# Calculate time per kernels \n",
    "    Theoretical tiling (done)\n",
    "    Hierarchical cache (P3)\n",
    "    Realistic tiling (P4)\n",
    "# Output \n",
    "    Breakdown between different kernels and the shape of the tensors (Done)\n",
    "    Estimated execution time for different kernels (Done)\n",
    "    Estimated activities for different kernels for power analysis (P6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b37cc10",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59972076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Setup\n",
    "# Variables: the input/output token length\n",
    "token_lengths = [\n",
    "    (1024, 1024),\n",
    "    (8192, 1024)\n",
    "]\n",
    "# Variables: workload characteristics\n",
    "bytes_per_value = 2\n",
    "# To-do list: mixed precision between weights and activations (P6)\n",
    "\n",
    "# Variables: parallelism (P4)\n",
    "\n",
    "# Variables: types of layers\n",
    "Ma_Mw = \"Ma_Mw\" # The first matrix is the activations, the second matrix is the weights\n",
    "Ma_Mqa = \"Ma_Mqa\" # The first matrix is the activations, the second matrix is the grouped activations (special usages for QGA)\n",
    "Mw_Ma = \"Mw_Ma\" # The first matrix is the weights, the second matrix is the activations\n",
    "Ma_Ma = \"Ma_Ma\" # The first matrix is the activations, the second matrix is the activations\n",
    "\n",
    "Va_Mw = \"Va_Mw\" # The first vector is the activations, the second matrix is the weights\n",
    "Va_Mqa = \"Va_Mqa\" # The first vector is the activations, the second matrix is the grouped activations (special usages for QGA)\n",
    "Vw_Va = \"Vw_Va\" # The first vector is the weights, the second vector is the activations\n",
    "Va_Va = \"Va_Va\" # The first vector is the activations, the second vector is the activations\n",
    "\n",
    "KVCache = \"KVCache\" # This is to capture the retrieval of the key/value cache\n",
    "Async_KVCache = \"Async_KVCache\" # This is to capture the store (and some retrieval) of the key/value cache\n",
    "\n",
    "# Flags for debug and detailed print outputs\n",
    "DEBUG_PRINT = True\n",
    "DETAIL_PRINT = True "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57903e3f",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3dfcf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts an integer number into a size string with M, G, T, P suffix.\n",
    "def convert_number_to_string(count):\n",
    "    # Define the suffixes for bytes, terabytes, and petabytes\n",
    "    suffixes = [\"M\", \"G\", \"T\", \"P\"]\n",
    "    # Define the corresponding byte multiples\n",
    "    multiples = [1024**2, 1024**3, 1024**4, 1024**5]\n",
    "\n",
    "    # Iterate over the multiples in reverse to find the largest fitting multiple\n",
    "    for i in reversed(range(len(multiples))):\n",
    "        if count >= multiples[i]:\n",
    "            size = count / multiples[i]  # Calculate the size in the corresponding unit\n",
    "            return f\"{size:.1f}{suffixes[i]}\"  # Return the formatted size string\n",
    "    # If the count is less than 1B, return it as a string\n",
    "    return str(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3102ad19",
   "metadata": {},
   "source": [
    "Read model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9b0fcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Configuration:\n",
      "\tHidden Size: 4096\n",
      "\tIntermediate Size: 14336\n",
      "\tNumber of Attention Heads: 32\n",
      "\tNumber of Key-Value Heads: 8\n",
      "\tNumber of Hidden Layers: 32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "READ_FROM_LOCAL = False # Set to True if you want to read the config.json from local disk\n",
    "\n",
    "if READ_FROM_LOCAL:\n",
    "    import os\n",
    "\n",
    "    # Read config.json from local disk \n",
    "    # Specify the input file folder\n",
    "    input_folder = r\"C:\\Users\\ychen4\\OneDrive - Intel Corporation\\Desktop\\devtool\\modelsize\"\n",
    "    config_file = \"config-8B.json\"\n",
    "    config_path = os.path.join(input_folder, config_file)\n",
    "\n",
    "    with open(config_path, \"r\") as file:\n",
    "        data = json.load(file)  # Parse the JSON file into a Python dictionary\n",
    "else:\n",
    "    # Download the model config from HuggingFace.\n",
    "    # Uncomment the following lines if you need to install the required packages\n",
    "    #%pip install huggingface_hub\n",
    "    #%pip install ipywidgets\n",
    "    #%pip install dotenv\n",
    "    # Log in to HuggingFace Hub from your Jupyter notebook\n",
    "    from huggingface_hub import hf_hub_download, login\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    login(token=os.getenv(\"HF_TOKEN\"))\n",
    "    # please store your HuggingFace token in a .env file in the same folder as this notebook\n",
    "    # If you don't have a HuggingFace token, please create one at https://huggingface.co/settings/tokens\n",
    "\n",
    "    model_repo_id = \"meta-llama/Llama-3.1-8B\" # https://huggingface.co/meta-llama/Llama-3.1-8B\n",
    "\n",
    "    downloaded_path = hf_hub_download(repo_id=model_repo_id, filename=\"config.json\")\n",
    "    with open(downloaded_path, \"r\") as file:\n",
    "        data = json.load(file)  # Parse the JSON file into a Python dictionary\n",
    "\n",
    "# Extract relevant values from the JSON data\n",
    "class LLMConfig:\n",
    "    def __init__(self, data):\n",
    "        self.hidden_size = data[\"hidden_size\"]\n",
    "        self.intermediate_size = data[\"intermediate_size\"]\n",
    "        self.num_q_heads = data[\"num_attention_heads\"]\n",
    "        self.num_kv_heads = data[\"num_key_value_heads\"]\n",
    "        self.num_hidden_layers = data[\"num_hidden_layers\"]\n",
    "        self.sub_dmodel = self.hidden_size // self.num_q_heads\n",
    "        self.grouped_q = self.num_q_heads / self.num_kv_heads\n",
    "\n",
    "llm = LLMConfig(data)\n",
    "\n",
    "if DEBUG_PRINT:\n",
    "    print (\"LLM Configuration:\")\n",
    "    print(\"\\tHidden Size:\", llm.hidden_size)\n",
    "    print(\"\\tIntermediate Size:\", llm.intermediate_size)\n",
    "    print(\"\\tNumber of Attention Heads:\", llm.num_q_heads)\n",
    "    print(\"\\tNumber of Key-Value Heads:\", llm.num_kv_heads)\n",
    "    print(\"\\tNumber of Hidden Layers:\", llm.num_hidden_layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a912bc",
   "metadata": {},
   "source": [
    "Read hardware specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "968a4da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected architecture: JGS\n",
      "Num_Cores            1.920000e+02\n",
      "Frequency            1.500000e+09\n",
      "MACs_per_cycle       8.192000e+03\n",
      "Bandwidth            3.298535e+13\n",
      "L3_cache_capacity    1.258291e+08\n",
      "MACs_per_second      2.359296e+15\n",
      "Name: JGS, dtype: float64\n",
      "MACs_per_second: 2359296000000000.0\n"
     ]
    }
   ],
   "source": [
    "# To-Do: Read detailed hardware specification from spreadsheet (P2)\n",
    "#%pip install pandas\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 400)\n",
    "pd.set_option('display.width', 400)\n",
    "\n",
    "# Define hardware specs for multiple architectures\n",
    "HW_SPEC_DF = pd.DataFrame({\n",
    "    \"NVL-AX\": {\n",
    "        \"Num_Cores\": 32,                        # Number of cores\n",
    "        \"Frequency\": 2.5 * 1e9,                 # Frequency in Hz\n",
    "        \"MACs_per_cycle\": 2*1024,               # 2K MACs per cycle per core for FP16 (depth = 8)\n",
    "        \"Bandwidth\": 342*1024*1024*1024,        # 342 GB/s \n",
    "        \"L3_cache_capacity\": 36*1024*1024,      # 36 MB\n",
    "    },\n",
    "    \"JGS\": {\n",
    "        \"Num_Cores\": 192,                       # Number of cores\n",
    "        \"Frequency\": 1.5 * 1e9,                 # Frequency in Hz\n",
    "        \"MACs_per_cycle\": 8*1024,               # 8K MACs per cycle per core for FP32\n",
    "        \"Bandwidth\": 30*1024*1024*1024*1024,    # 30 TB/s \n",
    "        \"L3_cache_capacity\": 120*1024*1024,     # 120 MB\n",
    "    }\n",
    "})\n",
    "\n",
    "# Add derived row for MACs_per_second\n",
    "HW_SPEC_DF.loc[\"MACs_per_second\"] = (\n",
    "    HW_SPEC_DF.loc[\"Num_Cores\"] * HW_SPEC_DF.loc[\"Frequency\"] * HW_SPEC_DF.loc[\"MACs_per_cycle\"]\n",
    ")\n",
    "\n",
    "# Select active architecture\n",
    "arch = \"JGS\" # \"NVL-AX\"  \n",
    "HW_SPEC = HW_SPEC_DF[arch]\n",
    "\n",
    "# Example usage:\n",
    "if DEBUG_PRINT:\n",
    "    print(\"Selected architecture:\", arch)\n",
    "    print(HW_SPEC)\n",
    "    print(\"MACs_per_second:\", HW_SPEC[\"MACs_per_second\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608a1c7d",
   "metadata": {},
   "source": [
    "Breakdown the models into different kernels/tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dad35895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do: (1) MOE model, (2) auto-conversion, (3) parallelism \n",
    "\n",
    "class WorkloadProfile:\n",
    "    def __init__(self):\n",
    "        self.layers = pd.DataFrame(columns=[\n",
    "            \"type\", \"name\", \"m\", \"k\", \"n\", \"batch_size\", \"grouped_q\", \"compute\", \"weight\", \"kv_cache\"\n",
    "        ])\n",
    "        self.total_compute = 0\n",
    "        self.total_weight = 0\n",
    "        self.total_kv_cache = 0\n",
    "\n",
    "    def add_layer(self, layer_type, name, *args, **kwargs):\n",
    "        dim_m = args[0]\n",
    "        dim_k = args[1]\n",
    "        dim_n = args[2]\n",
    "        batch_size = args[3]\n",
    "        grouped_q = kwargs.get('grouped_q', 1)\n",
    "        compute = None\n",
    "        weight = None\n",
    "        kv_cache = None\n",
    "        if grouped_q > 1 and layer_type not in [\"Ma_Mqa\", \"Va_Mqa\"]:\n",
    "            raise ValueError(f\"Invalid layer type {layer_type} for grouped_q > 1\")\n",
    "        match layer_type:\n",
    "            case \"Ma_Mw\":\n",
    "                compute = dim_m * dim_k * dim_n * batch_size\n",
    "                weight = dim_k * dim_n\n",
    "            case \"Ma_Mqa\":\n",
    "                compute = dim_m * grouped_q * dim_k * dim_n * batch_size\n",
    "            case \"Mw_Ma\":\n",
    "                compute = dim_m * dim_k * dim_n * batch_size\n",
    "                weight = dim_m * dim_k\n",
    "            case \"Ma_Ma\":\n",
    "                compute = dim_m * dim_k * dim_n * batch_size\n",
    "            case \"Va_Mw\":\n",
    "                compute = dim_m * dim_k * dim_n * batch_size\n",
    "                weight = dim_k * dim_n\n",
    "            case \"Va_Mqa\":\n",
    "                compute = dim_m * grouped_q * dim_k * dim_n * batch_size\n",
    "            case \"Vw_Va\":\n",
    "                compute = dim_m * dim_k * dim_n * batch_size\n",
    "                weight = dim_m * dim_k\n",
    "            case \"Va_Va\":\n",
    "                compute = dim_m * dim_k * dim_n * batch_size\n",
    "            case \"KVCache\":\n",
    "                kv_cache = dim_m * dim_k * dim_n * batch_size\n",
    "            case \"Async_KVCache\":\n",
    "                kv_cache = dim_m * dim_k * dim_n * batch_size\n",
    "            case _:\n",
    "                raise ValueError(f\"Unknown layer_type: {layer_type}\")\n",
    "        new_row = {\n",
    "            \"type\": layer_type,\n",
    "            \"name\": name,\n",
    "            \"m\": dim_m,\n",
    "            \"k\": dim_k,\n",
    "            \"n\": dim_n,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"grouped_q\": grouped_q,\n",
    "            \"compute\": compute,\n",
    "            \"weight\": weight,\n",
    "            \"kv_cache\": kv_cache\n",
    "        }\n",
    "        self.layers = pd.concat([self.layers, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    def sum_totals(self):\n",
    "        self.layers[\"compute\"] = self.layers[\"compute\"].infer_objects(copy=False)\n",
    "        self.total_compute = self.layers[\"compute\"].fillna(0).sum()\n",
    "        self.layers[\"weight\"] = self.layers[\"weight\"].infer_objects(copy=False)\n",
    "        self.total_weight = self.layers[\"weight\"].fillna(0).sum()\n",
    "        self.layers[\"kv_cache\"] = self.layers[\"kv_cache\"].infer_objects(copy=False)\n",
    "        self.total_kv_cache = self.layers[\"kv_cache\"].fillna(0).sum()\n",
    "\n",
    "def perform_prefill(llm, seq_length, p_batch_size):\n",
    "    # Note some parts of the transformer are not modeled, e.g., \n",
    "    # Input and position embedding\n",
    "    # Softmax\n",
    "    # Residual connection and layer normalization\n",
    "    # Task-specific output layer\n",
    "\n",
    "    # Create a WorkloadProfile instance\n",
    "    wl = WorkloadProfile()\n",
    "\n",
    "    # Add layers using the WorkloadProfile object\n",
    "    wl.add_layer(Ma_Mw, \"Q/K/V*W\", seq_length, llm.hidden_size, llm.sub_dmodel * (llm.num_q_heads+llm.num_kv_heads*2), p_batch_size)\n",
    "    wl.add_layer(Ma_Mqa, \"Q*gK\", seq_length, llm.hidden_size, seq_length, p_batch_size, qrouped_q=llm.grouped_q)\n",
    "    wl.add_layer(Ma_Mqa, \"Q*gK*gV\", seq_length, llm.hidden_size, seq_length, p_batch_size, qrouped_q=llm.grouped_q)\n",
    "    wl.add_layer(Ma_Mw, \"O*W\", seq_length, llm.hidden_size, llm.hidden_size, p_batch_size)\n",
    "    wl.add_layer(Ma_Mw, \"FFN_up\", seq_length, llm.hidden_size, llm.intermediate_size, p_batch_size)\n",
    "    wl.add_layer(Ma_Mw, \"FFN_gate\", seq_length, llm.hidden_size, llm.intermediate_size, p_batch_size)\n",
    "    wl.add_layer(Ma_Mw, \"FFN_down\", seq_length, llm.intermediate_size, llm.hidden_size, p_batch_size)\n",
    "    # add memory to KV cache #### More optimization opportunity (P1)\n",
    "    wl.add_layer(Async_KVCache, \"KVCache_Store\", seq_length, llm.sub_dmodel, 2*llm.num_kv_heads, p_batch_size)\n",
    "\n",
    "    # Sum up the compute and memory usage\n",
    "    wl.sum_totals()\n",
    "\n",
    "    if DEBUG_PRINT:\n",
    "        print(\"\")\n",
    "        print(\"======== Prefill Workload Profile ========\")\n",
    "        print(\"Prefill Compute\", wl.total_compute)\n",
    "        print(\"Prefill Weights\", wl.total_weight)\n",
    "        print(\"Prefill KV cache\", wl.total_kv_cache)\n",
    "        print(wl.layers)\n",
    "\n",
    "\n",
    "    # Print detailed information if the flag is set\n",
    "    if DETAIL_PRINT:\n",
    "        print(\"\")\n",
    "        print(\"   Details:\")\n",
    "        print(\"   === Input parameters ===\")\n",
    "        print(\"   Context length:\", seq_length)\n",
    "        print(\"   Bytes per FP value:\", bytes_per_value) # To-Do: this is set globally, not specific to the model or workload (P2)\n",
    "        print(\"   Layers:\", llm.num_hidden_layers)\n",
    "\n",
    "        print(\"   Total Compute (MACs):\", convert_number_to_string(wl.total_compute * llm.num_hidden_layers))\n",
    "        print(\"   Total Weights Footprint (Bytes):\", convert_number_to_string(wl.total_weight * llm.num_hidden_layers))\n",
    "        print(\"   Total KV Cache Footprint (Bytes):\", convert_number_to_string(wl.total_kv_cache * llm.num_hidden_layers))\n",
    "\n",
    "    return wl\n",
    "\n",
    "def perform_decode(llm, context_length, d_batch_size): # Decoding one token at a time\n",
    "    # Create a WorkloadProfile instance\n",
    "    wl = WorkloadProfile()\n",
    "\n",
    "    # Add layers using the WorkloadProfile object\n",
    "    wl.add_layer(Va_Mw, \"Q/K/V*W\", 1, llm.hidden_size, llm.sub_dmodel * (llm.num_q_heads+2*llm.num_kv_heads), d_batch_size)\n",
    "    wl.add_layer(KVCache, \"KVCache_Read\", context_length, llm.sub_dmodel, 2*llm.num_kv_heads, d_batch_size)\n",
    "    wl.add_layer(Va_Mqa, \"Q*gK\", 1, llm.hidden_size, context_length, d_batch_size, qrouped_q=llm.grouped_q)\n",
    "    wl.add_layer(Va_Mqa, \"Q*gK*gV\", 1, llm.hidden_size, context_length, d_batch_size, qrouped_q=llm.grouped_q)\n",
    "    wl.add_layer(Va_Mw, \"O*W\", 1, llm.hidden_size, llm.hidden_size, d_batch_size)\n",
    "    wl.add_layer(Va_Mw, \"FFN_up\", 1, llm.hidden_size, llm.intermediate_size, d_batch_size)\n",
    "    wl.add_layer(Va_Mw, \"FFN_gate\", 1, llm.hidden_size, llm.intermediate_size, d_batch_size)\n",
    "    wl.add_layer(Va_Mw, \"FFN_down\", 1, llm.intermediate_size, llm.hidden_size, d_batch_size)\n",
    "    # add the last token to KV cache #### More optimization opportunity (P1)\n",
    "\n",
    "    # Sum up the compute and memory usage\n",
    "    wl.sum_totals()\n",
    "\n",
    "    if DEBUG_PRINT:\n",
    "        print(\"\")\n",
    "        print(\"======== Decode Workload Profile ========\")\n",
    "        print(\"Decode Compute\", wl.total_compute)\n",
    "        print(\"Decode Weights\", wl.total_weight)\n",
    "        print(\"Decode KV cache\", wl.total_kv_cache)\n",
    "        print(wl.layers)\n",
    "\n",
    "    # Print detailed information if the flag is set\n",
    "    if DETAIL_PRINT:\n",
    "        print(\"\")\n",
    "        print(\"   Details:\")\n",
    "        print(\"   === Input parameters ===\")\n",
    "        print(\"   Context length:\", context_length)\n",
    "        print(\"   Bytes per FP value:\", bytes_per_value) # To-Do: this is set globally, not specific to the model or workload (P2)\n",
    "        print(\"   Layers:\", llm.num_hidden_layers)\n",
    "\n",
    "        print(\"   Total Compute (MACs):\", convert_number_to_string(wl.total_compute * llm.num_hidden_layers))\n",
    "        print(\"   Total Weights Footprint (Bytes):\", convert_number_to_string(wl.total_weight * llm.num_hidden_layers))\n",
    "        print(\"   Total KV Cache Footprint (Bytes):\", convert_number_to_string(wl.total_kv_cache * llm.num_hidden_layers))\n",
    "\n",
    "    return wl\n",
    "\n",
    "def perform_chunkedprefill(llm, p_context_length, p_tokens, d_context_length, d_tokens): # Decoding one token at a time\n",
    "    # Create a WorkloadProfile instance\n",
    "    wl = WorkloadProfile()\n",
    "\n",
    "    # Add layers using the profile object\n",
    "    wl.add_layer(Ma_Mw, \"Q/K/V*W\", (p_tokens+d_tokens), llm.hidden_size, llm.sub_dmodel * (llm.num_q_heads+llm.num_kv_heads*2), 1)\n",
    "\n",
    "    # decode token attention\n",
    "    wl.add_layer(KVCache, \"dKVCache_Read\", d_context_length, llm.sub_dmodel, 2*llm.num_kv_heads, d_tokens)\n",
    "    wl.add_layer(Va_Mqa, \"dQ*gK\", 1, llm.hidden_size, llm.sub_dmodel * llm.num_kv_heads, d_tokens, qrouped_q=llm.grouped_q)\n",
    "    wl.add_layer(Va_Mqa, \"dQ*gK*gV\", 1, llm.hidden_size, llm.sub_dmodel * llm.num_kv_heads, d_tokens, qrouped_q=llm.grouped_q)\n",
    "\n",
    "    # prefill token attention\n",
    "    wl.add_layer(Async_KVCache, \"pKVCache_Read\", p_context_length, llm.sub_dmodel, 2*llm.num_kv_heads, 1)\n",
    "    wl.add_layer(Ma_Mqa, \"pQ*gK\", p_tokens, llm.hidden_size, p_context_length, 1, qrouped_q=llm.grouped_q)\n",
    "    wl.add_layer(Ma_Mqa, \"pQ*gK*gV\", p_tokens, llm.hidden_size, p_context_length, 1, qrouped_q=llm.grouped_q)\n",
    "    wl.add_layer(Async_KVCache, \"KVCache_Store\", p_tokens, llm.sub_dmodel, 2*llm.num_kv_heads, 1)\n",
    "\n",
    "    wl.add_layer(Ma_Mw, \"O*W\", (p_tokens+d_tokens), llm.hidden_size, llm.hidden_size, 1)\n",
    "    wl.add_layer(Ma_Mw, \"FFN_up\", (p_tokens+d_tokens), llm.hidden_size, llm.intermediate_size, 1)\n",
    "    wl.add_layer(Ma_Mw, \"FFN_gate\", (p_tokens+d_tokens), llm.hidden_size, llm.intermediate_size, 1)\n",
    "    wl.add_layer(Ma_Mw, \"FFN_down\", (p_tokens+d_tokens), llm.intermediate_size, llm.hidden_size, 1)\n",
    "\n",
    "    # Sum up the compute and memory usage\n",
    "    wl.sum_totals()\n",
    "\n",
    "    if DEBUG_PRINT:\n",
    "        print(\"\")\n",
    "        print(\"======== Chunked Prefill Workload Profile ========\")\n",
    "        print(\"Chunked Compute\", wl.total_compute)\n",
    "        print(\"Chunked Weights\", wl.total_weight)\n",
    "        print(\"Chunked KV cache\", wl.total_kv_cache)\n",
    "        print(wl.layers)\n",
    "\n",
    "    # Print detailed information if the flag is set\n",
    "    if DETAIL_PRINT:\n",
    "        print(\"\")\n",
    "        print(\"   Details:\")\n",
    "        print(\"   === Input parameters ===\")\n",
    "        print(\"   Prefill context length:\", p_context_length)\n",
    "        print(\"   Decode context length:\", d_context_length)\n",
    "        print(\"   Bytes per FP value:\", bytes_per_value) # To-Do: this is set globally, not specific to the model or workload (P2)\n",
    "        print(\"   Layers:\", llm.num_hidden_layers)\n",
    "\n",
    "        print(\"   Total Compute (MACs):\", convert_number_to_string(wl.total_compute * llm.num_hidden_layers))\n",
    "        print(\"   Total Weights Footprint (Bytes):\", convert_number_to_string(wl.total_weight * llm.num_hidden_layers))\n",
    "        print(\"   Total KV Cache Footprint (Bytes):\", convert_number_to_string(wl.total_kv_cache * llm.num_hidden_layers))\n",
    "\n",
    "    return wl\n",
    "\n",
    "def perform_GEMM(dim_m, dim_k, dim_n): # Decoding one token at a time\n",
    "    # Create a WorkloadProfile instance\n",
    "    wl = WorkloadProfile()\n",
    "\n",
    "    # Add layers using the profile object\n",
    "    wl.add_layer(Ma_Ma, \"GEMM\", dim_m, dim_k, dim_n, 1)\n",
    "\n",
    "    return wl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050367e0",
   "metadata": {},
   "source": [
    "Kernel breakdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "71b3428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first tuple in token_lengths\n",
    "\n",
    "if 0:\n",
    "#for token_length in token_lengths:\n",
    "    # Unpack the tuple into two variables\n",
    "    input_length, output_length = token_lengths\n",
    "    print(\"Input length:\", input_length)\n",
    "    print(\"Output length:\", output_length)\n",
    "    p_batch_size = 1\n",
    "    d_batch_size = 256\n",
    "    chunksize = 256\n",
    "\n",
    "    # Perform prefill\n",
    "    perform_prefill(llm, input_length, p_batch_size)\n",
    "    # Perform decode\n",
    "    perform_decode(llm, input_length, d_batch_size)    \n",
    "    # Perform chunked prefill\n",
    "    d_tokens = chunksize * output_length // (input_length + output_length)\n",
    "    p_tokens = chunksize - d_tokens\n",
    "    d_context_length = input_length + output_length // 2    # This is used to approximately the average decode computation\n",
    "    p_context_length = int(input_length / 1.73 - p_tokens//2)             # 1.73 = sqrt(3) This is used to approximately the average prefill computation\n",
    "\n",
    "    perform_chunkedprefill(llm, p_context_length, p_tokens, d_context_length, d_tokens)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd388892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#### Calculate time per kernels \n",
    "# Realistic tiling (P3)\n",
    "\n",
    "def estimate_tiling_sizes(cache_size, bytes_per_value, num_fixed_dims, *dims):\n",
    "    \"\"\"\n",
    "    Estimate tiling sizes for matrix multiplication given cache_size, bytes_per_value, and some fixed dimensions.\n",
    "    If num_fixed_dims > 0, dims should provide the fixed dimensions in order (dim_1, dim_2, dim_3).\n",
    "    The remaining dimensions will be estimated to fit the cache.\n",
    "\n",
    "    Args:\n",
    "        cache_size: total cache size available (e.g., L3 cache)\n",
    "        bytes_per_value: bytes per matrix element\n",
    "        num_fixed_dims: number of fixed dimensions provided (0-2)\n",
    "        *dims: the fixed dimension values (dim_m, dim_k, dim_n) in order\n",
    "\n",
    "    Returns:\n",
    "        tuple: (dim_m, dim_k, dim_n) estimated tile sizes\n",
    "    \"\"\"\n",
    "    match num_fixed_dims:\n",
    "        case 0:\n",
    "            # Assume cache is split equally among the three matrices\n",
    "            size_per_matrix = cache_size / 3\n",
    "            # For cubic root, use **(1/3)\n",
    "            perfect_dim = (size_per_matrix / bytes_per_value) ** (1/2)\n",
    "            return perfect_dim\n",
    "        case 1:\n",
    "            # Solve for x in: x * x + 2 * fixed_dim * x < cache_size / bytes_per_value\n",
    "            # Rearranged: x^2 + 2 * fixed_dim * x - (cache_size / bytes_per_value) < 0\n",
    "            # Use quadratic formula: x = (-b + sqrt(b^2 - 4ac)) / 2a, where a=1, b=2*fixed_dim, c=-(cache_size / bytes_per_value)\n",
    "            b = dims[0]*2\n",
    "            discriminant = b**2 + 4 * (cache_size / bytes_per_value)\n",
    "            dim_2 = (-b + math.sqrt(discriminant)) / 2\n",
    "            return dim_2\n",
    "        case 2:\n",
    "            # Because the third dimension is not fixed, we can use the remaining cache space\n",
    "            # to estimate the third dimension\n",
    "            remaining_capacity = (cache_size - (dims[0] * dims[1] * bytes_per_value))\n",
    "            dim_3 = remaining_capacity / (bytes_per_value * (dims[0]+dims[1]))\n",
    "            return dim_3\n",
    "        \n",
    "# Simple roofline: If matrix-matrix operations, assume compute bound.  If matrix-vector operations, assume memory bound.\n",
    "# Assume wl is a WorkloadProfile instance (from perform_prefill, perform_decode, or perform_chunkedprefill)\n",
    "# HW_SPEC should define MACs_per_second, L3_cache_capacity, Bandwidth, and Frequency\n",
    "import numpy as np\n",
    "def estimate_kernel_times_by_theoretical_tiler(wl, HW_SPEC):\n",
    "    # Theoretical tiling: the best tiling used all the cache space for matrix A, matrix B, and matrix C\n",
    "    # Add new columns if not present\n",
    "    for col, dtype in [\n",
    "        (\"best_tiler\", object),\n",
    "        (\"exec_cycle\", float),\n",
    "        (\"cmp_cycle\", float),\n",
    "        (\"mem_cycle\", float),\n",
    "        (\"mem_to_cmp_ratio\", float),\n",
    "        (\"bound\", object)\n",
    "    ]:\n",
    "        if col not in wl.layers.columns:\n",
    "            wl.layers[col] = pd.Series([None]*len(wl.layers), dtype=dtype)\n",
    "\n",
    "    for idx, layer in wl.layers.iterrows():\n",
    "        layer_type = layer[\"type\"]\n",
    "        best_tiler = None\n",
    "        cmp_cycle = None\n",
    "        mem_cycle = None\n",
    "        mem_cycle_to_cmp_cycle = None\n",
    "        exec_cycle = None\n",
    "        layer_bound = None\n",
    "        if \"M\" in layer_type or \"w\" in layer_type:\n",
    "            if not pd.isna(layer[\"compute\"]):\n",
    "                L3_cache_capacity = HW_SPEC[\"L3_cache_capacity\"]\n",
    "                wldims = [layer[\"m\"], layer[\"k\"], layer[\"n\"]]\n",
    "                batch_size = layer[\"batch_size\"]\n",
    "\n",
    "                # Step 0: use batch size to adjust dimensions so that the output matrix is as closer to square as possible\n",
    "                if batch_size > 1:\n",
    "                    if wldims[0] > wldims[2] and wldims[0] / wldims[2] > batch_size:\n",
    "                        wldims[2] = wldims[2] * batch_size\n",
    "                    elif wldims[2] > wldims[0] and wldims[2] / wldims[0] > batch_size:\n",
    "                        wldims[0] = wldims[0] * batch_size\n",
    "                    else:\n",
    "                        ratio = wldims[0] / wldims[2]\n",
    "                        batch_size = batch_size / ratio\n",
    "                        wldims[2] = wldims[0] = wldims[0] * ((batch_size) ** (1/2))\n",
    "\n",
    "                # Step 1: find the tiling dims when all 3 dims are flexible\n",
    "                t_dim = estimate_tiling_sizes(L3_cache_capacity, bytes_per_value, 0)\n",
    "                dims = [(0, wldims[0]), (1, wldims[1]), (2, wldims[2])]\n",
    "                dims_sorted = sorted(dims, key=lambda x: x[1])\n",
    "                if dims_sorted[0][1] >= t_dim:\n",
    "                    tile_dims = [(0, t_dim), (1, t_dim), (2, t_dim)]\n",
    "                else: # Step 2: find the tiling dims when 1 dim (the smallest) is fixed\n",
    "                    t_dim = estimate_tiling_sizes(L3_cache_capacity, bytes_per_value, 1, dims_sorted[0][1])\n",
    "                    if dims_sorted[1][1] >= t_dim:\n",
    "                        dims_sorted[1] = (dims_sorted[1][0], t_dim)\n",
    "                        dims_sorted[2] = (dims_sorted[2][0], t_dim)\n",
    "                        tile_dims = sorted(dims_sorted, key=lambda x: x[0])\n",
    "                    else: # Step 3: find the last tiling dim when the smallest 2 dims are fixed\n",
    "                        t_dim = estimate_tiling_sizes(L3_cache_capacity, bytes_per_value, 2, dims_sorted[0][1], dims_sorted[1][1])\n",
    "                        if dims_sorted[2][1] >= t_dim:\n",
    "                            dims_sorted[2] = (dims_sorted[2][0], t_dim)\n",
    "                            tile_dims = sorted(dims_sorted, key=lambda x: x[0])\n",
    "                        else:\n",
    "                            tile_dims = sorted(dims_sorted, key=lambda x: x[0])\n",
    "\n",
    "                best_tiler = f\"{tile_dims[0][1]:.1f}x{tile_dims[1][1]:.1f}x{tile_dims[2][1]:.1f}\"\n",
    "\n",
    "                # Step 4: compare the cmp_cycle and the mem_cycle and decide the bound\n",
    "                block_compute = tile_dims[0][1] * tile_dims[1][1] * tile_dims[2][1]\n",
    "                cmp_cycle = block_compute / HW_SPEC[\"MACs_per_second\"] * HW_SPEC[\"Frequency\"] * layer[\"compute\"]/block_compute\n",
    "                memory = (tile_dims[0][1] * tile_dims[1][1] + tile_dims[2][1] * tile_dims[1][1]) * bytes_per_value\n",
    "                mem_cycle = memory / HW_SPEC[\"Bandwidth\"] * HW_SPEC[\"Frequency\"] * layer[\"compute\"]/block_compute\n",
    "                mem_cycle_to_cmp_cycle = mem_cycle / cmp_cycle if cmp_cycle else np.nan\n",
    "\n",
    "                if cmp_cycle > mem_cycle:\n",
    "                    exec_cycle = cmp_cycle\n",
    "                    layer_bound = \"Compute\"\n",
    "                else:\n",
    "                    exec_cycle = mem_cycle\n",
    "                    layer_bound = \"Memory\"\n",
    "            else:\n",
    "                exec_cycle = np.nan\n",
    "                best_tiler = None\n",
    "                cmp_cycle = np.nan\n",
    "                mem_cycle = np.nan\n",
    "                mem_cycle_to_cmp_cycle = np.nan\n",
    "        elif layer_type == KVCache:\n",
    "            if not pd.isna(layer[\"kv_cache\"]):\n",
    "                memory = layer[\"kv_cache\"] * bytes_per_value\n",
    "                exec_cycle = memory / HW_SPEC[\"Bandwidth\"] * HW_SPEC[\"Frequency\"]\n",
    "                layer_bound = \"Memory\"\n",
    "            else:\n",
    "                exec_cycle = np.nan\n",
    "        elif layer_type == Async_KVCache:\n",
    "            exec_cycle = np.nan\n",
    "        else:\n",
    "            exec_cycle = np.nan\n",
    "        # Update DataFrame in place\n",
    "        wl.layers.at[idx, \"best_tiler\"] = best_tiler\n",
    "        wl.layers.at[idx, \"exec_cycle\"] = exec_cycle\n",
    "        wl.layers.at[idx, \"cmp_cycle\"] = cmp_cycle\n",
    "        wl.layers.at[idx, \"mem_cycle\"] = mem_cycle\n",
    "        wl.layers.at[idx, \"mem_to_cmp_ratio\"] = mem_cycle_to_cmp_cycle\n",
    "        wl.layers.at[idx, \"bound\"] = layer_bound\n",
    "    return wl.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15452045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input length: 8192\n",
      "\n",
      "======== Chunked Prefill Workload Profile ========\n",
      "Chunked Compute 129665564672.0\n",
      "Chunked Weights 218103808.0\n",
      "Chunked KV cache 529235968.0\n",
      "             type           name     m      k      n batch_size grouped_q       compute      weight     kv_cache\n",
      "0           Ma_Mw        Q/K/V*W   512   4096   6144          1         1  1.288490e+10  25165824.0          NaN\n",
      "1         KVCache  dKVCache_Read  8448    128     16         30         1           NaN         NaN  519045120.0\n",
      "2          Va_Mqa          dQ*gK     1   4096   1024         30         1  1.258291e+08         NaN          NaN\n",
      "3          Va_Mqa       dQ*gK*gV     1   4096   1024         30         1  1.258291e+08         NaN          NaN\n",
      "4   Async_KVCache  pKVCache_Read  4494    128     16          1         1           NaN         NaN    9203712.0\n",
      "5          Ma_Mqa          pQ*gK   482   4096   4494          1         1  8.872378e+09         NaN          NaN\n",
      "6          Ma_Mqa       pQ*gK*gV   482   4096   4494          1         1  8.872378e+09         NaN          NaN\n",
      "7   Async_KVCache  KVCache_Store   482    128     16          1         1           NaN         NaN     987136.0\n",
      "8           Ma_Mw            O*W   512   4096   4096          1         1  8.589935e+09  16777216.0          NaN\n",
      "9           Ma_Mw         FFN_up   512   4096  14336          1         1  3.006477e+10  58720256.0          NaN\n",
      "10          Ma_Mw       FFN_gate   512   4096  14336          1         1  3.006477e+10  58720256.0          NaN\n",
      "11          Ma_Mw       FFN_down   512  14336   4096          1         1  3.006477e+10  58720256.0          NaN\n",
      "\n",
      "   Details:\n",
      "   === Input parameters ===\n",
      "   Prefill context length: 4494\n",
      "   Decode context length: 8448\n",
      "   Bytes per FP value: 2\n",
      "   Layers: 32\n",
      "   Total Compute (MACs): 3.8T\n",
      "   Total Weights Footprint (Bytes): 6.5G\n",
      "   Total KV Cache Footprint (Bytes): 15.8G\n",
      "             type           name     m      k      n batch_size grouped_q       compute      weight     kv_cache            best_tiler    exec_cycle     cmp_cycle    mem_cycle  mem_to_cmp_ratio    bound\n",
      "0           Ma_Mw        Q/K/V*W   512   4096   6144          1         1  1.288490e+10  25165824.0          NaN   512.0x4096.0x6144.0   8192.000000   8192.000000  2479.553223          0.302680  Compute\n",
      "1         KVCache  dKVCache_Read  8448    128     16         30         1           NaN         NaN  519045120.0                  None  47206.878662           NaN          NaN               NaN   Memory\n",
      "2          Va_Mqa          dQ*gK     1   4096   1024         30         1  1.258291e+08         NaN          NaN    30.0x4096.0x1024.0    392.645597     80.000000   392.645597          4.908070   Memory\n",
      "3          Va_Mqa       dQ*gK*gV     1   4096   1024         30         1  1.258291e+08         NaN          NaN    30.0x4096.0x1024.0    392.645597     80.000000   392.645597          4.908070   Memory\n",
      "4   Async_KVCache  pKVCache_Read  4494    128     16          1         1           NaN         NaN    9203712.0                  None           NaN           NaN          NaN               NaN     None\n",
      "5          Ma_Mqa          pQ*gK   482   4096   4494          1         1  8.872378e+09         NaN          NaN   482.0x4096.0x4494.0   5640.906250   5640.906250  1853.704453          0.328618  Compute\n",
      "6          Ma_Mqa       pQ*gK*gV   482   4096   4494          1         1  8.872378e+09         NaN          NaN   482.0x4096.0x4494.0   5640.906250   5640.906250  1853.704453          0.328618  Compute\n",
      "7   Async_KVCache  KVCache_Store   482    128     16          1         1           NaN         NaN     987136.0                  None           NaN           NaN          NaN               NaN     None\n",
      "8           Ma_Mw            O*W   512   4096   4096          1         1  8.589935e+09  16777216.0          NaN   512.0x4096.0x4096.0   5461.333333   5461.333333  1716.613770          0.314321  Compute\n",
      "9           Ma_Mw         FFN_up   512   4096  14336          1         1  3.006477e+10  58720256.0          NaN  512.0x4096.0x13198.2  19114.666667  19114.666667  5547.753696          0.290235  Compute\n",
      "10          Ma_Mw       FFN_gate   512   4096  14336          1         1  3.006477e+10  58720256.0          NaN  512.0x4096.0x13198.2  19114.666667  19114.666667  5547.753696          0.290235  Compute\n",
      "11          Ma_Mw       FFN_down   512  14336   4096          1         1  3.006477e+10  58720256.0          NaN  512.0x13198.2x4096.0  19114.666667  19114.666667  6008.148193          0.314321  Compute\n",
      "Total compute-bound cycles: 82279\n",
      "Total memory-bound cycles: 47992\n"
     ]
    }
   ],
   "source": [
    "### Output \n",
    "\n",
    "pd.set_option('display.max_colwidth', 400)\n",
    "pd.set_option('display.width', 400)\n",
    "\n",
    "# Estimated execution time for different kernels (P2)\n",
    "# Estimated activities for different kernels for power analysis (P6)\n",
    "\n",
    "# Breakdown between different kernels and the shape of the tensors: Mw_Ma, Ma_Ma, Mw_Va, Vw_Va, Va_Va\n",
    "input_length = 8192\n",
    "output_length = 512\n",
    "p_batch_size = 1\n",
    "d_batch_size = 256\n",
    "chunksize = 512\n",
    "d_tokens = chunksize * output_length // (input_length + output_length)\n",
    "p_tokens = chunksize - d_tokens\n",
    "d_context_length = input_length + output_length // 2    # This is used to approximately the average decode computation\n",
    "p_context_length = int(input_length / 1.73 - p_tokens//2)             # 1.73 = sqrt(3) This is used to approximately the average prefill computation\n",
    "\n",
    "print(\"Input length:\", input_length)\n",
    "#wl = perform_prefill(llm, input_length, p_batch_size)\n",
    "#wl = perform_decode(llm, d_context_length, d_batch_size)    \n",
    "wl = perform_chunkedprefill(llm, p_context_length, p_tokens, d_context_length, d_tokens)    \n",
    "kernel_times = estimate_kernel_times_by_theoretical_tiler(wl, HW_SPEC)\n",
    "print (wl.layers)\n",
    "\n",
    "compute_cycles = kernel_times.loc[kernel_times[\"bound\"] == \"Compute\", \"exec_cycle\"].sum()\n",
    "memory_cycles = kernel_times.loc[kernel_times[\"bound\"] == \"Memory\", \"exec_cycle\"].sum()\n",
    "\n",
    "print(f\"Total compute-bound cycles: {compute_cycles:.0f}\")\n",
    "print(f\"Total memory-bound cycles: {memory_cycles:.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9664ab8",
   "metadata": {},
   "source": [
    "## Overall plan\n",
    "# Setup\n",
    "    Variables: the input/output token length, bytes_per_value, types of layers (Done)\n",
    "    Variables: parallelism (P4)\n",
    "    Mixed-precision (P6)\n",
    "# Read config.json\n",
    "    Read from local file (Done)\n",
    "    Read from HuggingFace (P5)\n",
    "# Read hardware specification\n",
    "    Read from Excel spreadsheet (P2)\n",
    "# Breakdown the models into different kernels/tensors\n",
    "    Manually breakdown the GQA models (done)\n",
    "    MOE models (P3)\n",
    "    Automatic model conversion (P4)\n",
    "# Calculate time per kernels \n",
    "    Simple roofline (done)\n",
    "    Theoretical tiling (done)\n",
    "    Hierarchical cache (P3)\n",
    "    Realistic tiling (P4)\n",
    "# Output \n",
    "    Breakdown between different kernels and the shape of the tensors: Mw_Ma, Ma_Ma, Mw_Va, Vw_Va, Va_Va (Done)\n",
    "    Estimated execution time for different kernels (Done)\n",
    "    Estimated activities for different kernels for power analysis (P6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b37cc10",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59972076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Setup\n",
    "# Variables: the input/output token length\n",
    "token_lengths = [\n",
    "    (1024, 1024),\n",
    "    (8192, 1024)\n",
    "]\n",
    "# Variables: workload characteristics\n",
    "bytes_per_value = 2\n",
    "# To-do list: mixed precision between weights and activations (P6)\n",
    "\n",
    "# Variables: parallelism (P4)\n",
    "\n",
    "# Variables: types of layers\n",
    "Ma_Mw = \"Ma_Mw\" # The first matrix is the activations, the second matrix is the weights\n",
    "Ma_Mqa = \"Ma_Mqa\" # The first matrix is the activations, the second matrix is the grouped activations (special usages for QGA)\n",
    "Mw_Ma = \"Mw_Ma\" # The first matrix is the weights, the second matrix is the activations\n",
    "Ma_Ma = \"Ma_Ma\" # The first matrix is the activations, the second matrix is the activations\n",
    "\n",
    "Va_Mw = \"Va_Mw\" # The first vector is the activations, the second matrix is the weights\n",
    "Va_Mqa = \"Va_Mqa\" # The first vector is the activations, the second matrix is the grouped activations (special usages for QGA)\n",
    "Vw_Va = \"Vw_Va\" # The first vector is the weights, the second vector is the activations\n",
    "Va_Va = \"Va_Va\" # The first vector is the activations, the second vector is the activations\n",
    "\n",
    "KVCache = \"KVCache\" # This is to capture the retrieval of the key/value cache\n",
    "Async_KVCache = \"Async_KVCache\" # This is to capture the store (and some retrieval) of the key/value cache\n",
    "\n",
    "# Flags for debug and detailed print outputs\n",
    "DEBUG_PRINT = True\n",
    "DETAIL_PRINT = True "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57903e3f",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3dfcf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts an integer number into a size string with M, G, T, P suffix.\n",
    "def convert_number_to_string(count):\n",
    "    # Define the suffixes for bytes, terabytes, and petabytes\n",
    "    suffixes = [\"M\", \"G\", \"T\", \"P\"]\n",
    "    # Define the corresponding byte multiples\n",
    "    multiples = [1024**2, 1024**3, 1024**4, 1024**5]\n",
    "\n",
    "    # Iterate over the multiples in reverse to find the largest fitting multiple\n",
    "    for i in reversed(range(len(multiples))):\n",
    "        if count >= multiples[i]:\n",
    "            size = count / multiples[i]  # Calculate the size in the corresponding unit\n",
    "            return f\"{size:.1f}{suffixes[i]}\"  # Return the formatted size string\n",
    "    # If the count is less than 1B, return it as a string\n",
    "    return str(count)\n",
    "\n",
    "# Function to print a list with a given name\n",
    "def print_list(name, list):\n",
    "    print(\"\\t==\", name, \"==\")\n",
    "    for item in list:\n",
    "        print(\"\\t\", item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3102ad19",
   "metadata": {},
   "source": [
    "Read model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9b0fcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do: Read from HuggingFace (P5)\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Read config.json from local disk \n",
    "# Specify the input file folder\n",
    "input_folder = r\"C:\\Users\\ychen4\\OneDrive - Intel Corporation\\Desktop\\devtool\\modelsize\"\n",
    "config_file = \"config-8B.json\"\n",
    "config_path = os.path.join(input_folder, config_file)\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    data = json.load(file)  # Parse the JSON file into a Python dictionary\n",
    "\n",
    "# Extract relevant values from the JSON data\n",
    "class LLMConfig:\n",
    "    def __init__(self, data):\n",
    "        self.hidden_size = data[\"hidden_size\"]\n",
    "        self.intermediate_size = data[\"intermediate_size\"]\n",
    "        self.num_q_heads = data[\"num_attention_heads\"]\n",
    "        self.num_kv_heads = data[\"num_key_value_heads\"]\n",
    "        self.num_hidden_layers = data[\"num_hidden_layers\"]\n",
    "        self.sub_dmodel = self.hidden_size // self.num_q_heads\n",
    "        self.grouped_q = self.num_q_heads / self.num_kv_heads\n",
    "\n",
    "llm = LLMConfig(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a912bc",
   "metadata": {},
   "source": [
    "Read hardware specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "968a4da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do: Read detailed hardware specification from spreadsheet (P2)\n",
    "\n",
    "# NVL-AX\n",
    "HW_SPEC = {\n",
    "    \"Num_Cores\": 32,                        # Number of cores\n",
    "    \"Frequency\": 3 * 1e9,                 # Frequency in Hz\n",
    "    #\"MACs_per_cycle\": 2*1024,               # 2K MACs per cycle per core for FP16 (depth = 8)\n",
    "    \"MACs_per_cycle\": 1*1024,               # 2K MACs per cycle per core for FP16 (depth = 4)\n",
    "    \"Bandwidth\": 342*1024*1024*1024,        # 342 GB/s \n",
    "    \"L3_cache_capacity\": 36*1024*1024,      # 36 MB\n",
    "    }\n",
    "\n",
    "\"\"\" \n",
    "# JGS\n",
    "HW_SPEC = {\n",
    "    \"Num_Cores\": 192,                       # Number of cores\n",
    "    \"Frequency\": 1.5 * 1e9,                 # Frequency in Hz\n",
    "    \"MACs_per_cycle\": 8*1024,               # 8K MACs per cycle per core for FP32\n",
    "    \"Bandwidth\": 30*1024*1024*1024*1024,    # 30 TB/s \n",
    "    \"L3_cache_capacity\": 120*1024*1024,     # 120 MB\n",
    "    }\n",
    "\"\"\"    \n",
    "HW_SPEC[\"MACs_per_second\"] = HW_SPEC[\"Num_Cores\"] * HW_SPEC[\"Frequency\"] * HW_SPEC[\"MACs_per_cycle\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608a1c7d",
   "metadata": {},
   "source": [
    "Breakdown the models into different kernels/tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dad35895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do: (1) MOE model, (2) auto-conversion, (3) parallelism \n",
    "\n",
    "class WorkloadProfile:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.compute = []\n",
    "        self.weight = []\n",
    "        self.kv_cache = []\n",
    "        self.total_compute = 0\n",
    "        self.total_weight = 0\n",
    "        self.total_kv_cache = 0\n",
    "\n",
    "    # Function to add compute usage to a list\n",
    "    def add_compute(self, list, name, m, k, n, batch_size):\n",
    "        # Calculate the number of computations\n",
    "        computations = m * k * n * batch_size\n",
    "        # Append the result to the list\n",
    "        list.append([computations, name, m, k, n, batch_size])\n",
    "\n",
    "    # Function to add memory usage to a list\n",
    "    def add_wmemory(self, list, name, m, n):\n",
    "        # Calculate the memory usage\n",
    "        memory = m * n\n",
    "        # Append the result to the list\n",
    "        list.append([memory, name, m, n])\n",
    "\n",
    "    # Function to add memory usage to a list\n",
    "    def add_kv_cache(self, list, name, m, n, batch_size):\n",
    "        # Calculate the memory usage\n",
    "        cache = m * n * batch_size\n",
    "        # Append the result to the list\n",
    "        list.append([cache, name, m, n, batch_size])\n",
    "\n",
    "    def add_layer(self, layer_type, name, *args, **kwargs):\n",
    "        dim_m = args[0]\n",
    "        dim_k = args[1]\n",
    "        dim_n = args[2]\n",
    "        batch_size = args[3]\n",
    "        grouped_q = kwargs.get('grouped_q', 1)\n",
    "        # Check if the layer type is valid\n",
    "        if grouped_q > 1 and layer_type not in [\"Ma_Mqa\", \"Va_Mqa\"]:\n",
    "            raise ValueError(f\"Invalid layer type {layer_type} for grouped_q > 1\")\n",
    "\n",
    "        match layer_type:\n",
    "            case \"Ma_Mw\":\n",
    "                self.add_compute(self.compute, name, dim_m, dim_k, dim_n, batch_size)\n",
    "                self.add_wmemory(self.weight, name, dim_k, dim_n)\n",
    "            case \"Ma_Mqa\":\n",
    "                self.add_compute(self.compute, name, dim_m*grouped_q, dim_k, dim_n, batch_size)\n",
    "                # more optimization opportunity (P1)\n",
    "            case \"Mw_Ma\":\n",
    "                self.add_compute(self.compute, name, dim_m, dim_k, dim_n, batch_size)\n",
    "                self.add_wmemory(self.weight, name, dim_m, dim_k)\n",
    "            case \"Ma_Ma\":\n",
    "                self.add_compute(self.compute, name, dim_m, dim_k, dim_n, batch_size)\n",
    "            case \"Va_Mw\":\n",
    "                self.add_compute(self.compute, name, dim_m, dim_k, dim_n, batch_size)\n",
    "                self.add_wmemory(self.weight, name, dim_k, dim_n)\n",
    "            case \"Va_Mqa\":\n",
    "                self.add_compute(self.compute, name, dim_m*grouped_q, dim_k, dim_n, batch_size)\n",
    "                # more optimization opportunity (P1)\n",
    "            case \"Vw_Va\":\n",
    "                self.add_compute(self.compute, name, dim_m, dim_k, dim_n, batch_size)\n",
    "                self.add_wmemory(self.weight, name, dim_m, dim_k)\n",
    "            case \"Va_Va\":\n",
    "                self.add_compute(self.compute, name, dim_m, dim_k, dim_n, batch_size)\n",
    "            case \"KVCache\":\n",
    "                self.add_kv_cache(self.kv_cache, name, dim_m, dim_k*dim_n, batch_size)\n",
    "            case \"Async_KVCache\":\n",
    "                self.add_kv_cache(self.kv_cache, name, dim_m, dim_k*dim_n, batch_size)\n",
    "            case _:\n",
    "                raise ValueError(f\"Unknown layer_type: {layer_type}\")\n",
    "\n",
    "        layer = {\n",
    "            \"type\": layer_type,\n",
    "            \"name\": name,\n",
    "            \"args\": args,\n",
    "            \"kwargs\": kwargs,\n",
    "        }\n",
    "        self.layers.append(layer)\n",
    "\n",
    "def perform_prefill(llm, seq_length, p_batch_size):\n",
    "    # Note some parts of the transformer are not modeled, e.g., \n",
    "    # Input and position embedding\n",
    "    # Softmax\n",
    "    # Residual connection and layer normalization\n",
    "    # Task-specific output layer\n",
    "\n",
    "    # Create a WorkloadProfile instance\n",
    "    wl = WorkloadProfile()\n",
    "\n",
    "    # Add layers using the WorkloadProfile object\n",
    "    wl.add_layer(Ma_Mw, \"Q/K/V*W\", seq_length, llm.hidden_size, llm.sub_dmodel * (llm.num_q_heads+llm.num_kv_heads*2), p_batch_size)\n",
    "    wl.add_layer(Ma_Mqa, \"Q*gK\", seq_length, llm.hidden_size, seq_length, p_batch_size, qrouped_q=llm.grouped_q)\n",
    "    wl.add_layer(Ma_Mqa, \"Q*gK*gV\", seq_length, llm.hidden_size, seq_length, p_batch_size, qrouped_q=llm.grouped_q)\n",
    "    wl.add_layer(Ma_Mw, \"O*W\", seq_length, llm.hidden_size, llm.hidden_size, p_batch_size)\n",
    "    wl.add_layer(Ma_Mw, \"FFN_up\", seq_length, llm.hidden_size, llm.intermediate_size, p_batch_size)\n",
    "    wl.add_layer(Ma_Mw, \"FFN_gate\", seq_length, llm.hidden_size, llm.intermediate_size, p_batch_size)\n",
    "    wl.add_layer(Ma_Mw, \"FFN_down\", seq_length, llm.intermediate_size, llm.hidden_size, p_batch_size)\n",
    "    # add memory to KV cache #### More optimization opportunity (P1)\n",
    "    wl.add_layer(Async_KVCache, \"KVCache_Store\", seq_length, llm.sub_dmodel, 2*llm.num_kv_heads, p_batch_size)\n",
    "\n",
    "    # Sum up the compute and memory usage\n",
    "    wl.total_compute = sum(item[0] for item in wl.compute)\n",
    "    wl.total_weight = sum(item[0] for item in wl.weight)\n",
    "    wl.total_kv_cache = sum(item[0] for item in wl.kv_cache)\n",
    "\n",
    "    if DEBUG_PRINT:\n",
    "        print(\"Prefill Compute\", wl.total_compute)\n",
    "        print(\"Prefill Weights\", wl.total_weight)\n",
    "        print(\"Prefill KV cache\", wl.total_kv_cache)\n",
    "        print_list(\"Prefill Compute\", wl.compute)\n",
    "        print_list(\"Prefill Weights\", wl.weight)\n",
    "        print_list(\"Prefill KV cache\", wl.kv_cache)\n",
    "\n",
    "    # Print detailed information if the flag is set\n",
    "    if DETAIL_PRINT:\n",
    "        print(\"\")\n",
    "        print(\"   Details:\")\n",
    "        print(\"   === Input parameters ===\")\n",
    "        print(\"   Context length:\", seq_length)\n",
    "        print(\"   Bytes per FP value:\", bytes_per_value) # To-Do: this is set globally, not specific to the model or workload (P2)\n",
    "        print(\"   Layers:\", llm.num_hidden_layers)\n",
    "\n",
    "        print(\"   Total Compute (MACs):\", convert_number_to_string(wl.total_compute * llm.num_hidden_layers))\n",
    "        print(\"   Total Weights Footprint (Bytes):\", convert_number_to_string(wl.total_weight * llm.num_hidden_layers))\n",
    "        print(\"   Total KV Cache Footprint (Bytes):\", convert_number_to_string(wl.total_kv_cache * llm.num_hidden_layers))\n",
    "\n",
    "    return wl\n",
    "\n",
    "def perform_decode(llm, context_length, d_batch_size): # Decoding one token at a time\n",
    "    # Create a WorkloadProfile instance\n",
    "    wl = WorkloadProfile()\n",
    "\n",
    "    # Add layers using the WorkloadProfile object\n",
    "    wl.add_layer(Va_Mw, \"Q/K/V*W\", 1, llm.hidden_size, llm.sub_dmodel * (llm.num_q_heads+2*llm.num_kv_heads), d_batch_size)\n",
    "    wl.add_layer(KVCache, \"KVCache_Read\", context_length, llm.sub_dmodel, 2*llm.num_kv_heads, d_batch_size)\n",
    "    wl.add_layer(Va_Mqa, \"Q*gK\", 1, llm.hidden_size, context_length, d_batch_size, qrouped_q=llm.grouped_q)\n",
    "    wl.add_layer(Va_Mqa, \"Q*gK*gV\", 1, llm.hidden_size, context_length, d_batch_size, qrouped_q=llm.grouped_q)\n",
    "    wl.add_layer(Va_Mw, \"O*W\", 1, llm.hidden_size, llm.hidden_size, d_batch_size)\n",
    "    wl.add_layer(Va_Mw, \"FFN_up\", 1, llm.hidden_size, llm.intermediate_size, d_batch_size)\n",
    "    wl.add_layer(Va_Mw, \"FFN_gate\", 1, llm.hidden_size, llm.intermediate_size, d_batch_size)\n",
    "    wl.add_layer(Va_Mw, \"FFN_down\", 1, llm.intermediate_size, llm.hidden_size, d_batch_size)\n",
    "    # add the last token to KV cache #### More optimization opportunity (P1)\n",
    "\n",
    "    # Sum up the compute and memory usage\n",
    "    wl.total_compute = sum(item[0] for item in wl.compute)\n",
    "    wl.total_weight = sum(item[0] for item in wl.weight)\n",
    "    wl.total_kv_cache = sum(item[0] for item in wl.kv_cache)\n",
    "\n",
    "    if DEBUG_PRINT:\n",
    "        print(\"Decode Compute\", wl.total_compute)\n",
    "        print(\"Decode Weights\", wl.total_weight)\n",
    "        print(\"Decode KV cache\", wl.total_kv_cache)\n",
    "        print_list(\"Decode Compute\", wl.compute)\n",
    "        print_list(\"Decode Weights\", wl.weight)\n",
    "        print_list(\"Decode KV cache\", wl.kv_cache)\n",
    "\n",
    "    # Print detailed information if the flag is set\n",
    "    if DETAIL_PRINT:\n",
    "        print(\"\")\n",
    "        print(\"   Details:\")\n",
    "        print(\"   === Input parameters ===\")\n",
    "        print(\"   Context length:\", context_length)\n",
    "        print(\"   Bytes per FP value:\", bytes_per_value) # To-Do: this is set globally, not specific to the model or workload (P2)\n",
    "        print(\"   Layers:\", llm.num_hidden_layers)\n",
    "\n",
    "        print(\"   Total Compute (MACs):\", convert_number_to_string(wl.total_compute * llm.num_hidden_layers))\n",
    "        print(\"   Total Weights Footprint (Bytes):\", convert_number_to_string(wl.total_weight * llm.num_hidden_layers))\n",
    "        print(\"   Total KV Cache Footprint (Bytes):\", convert_number_to_string(wl.total_kv_cache * llm.num_hidden_layers))\n",
    "\n",
    "    return wl\n",
    "\n",
    "def perform_chunkedprefill(llm, p_context_length, p_tokens, d_context_length, d_tokens): # Decoding one token at a time\n",
    "    # Create a WorkloadProfile instance\n",
    "    wl = WorkloadProfile()\n",
    "\n",
    "    # Add layers using the profile object\n",
    "    wl.add_layer(Ma_Mw, \"Q/K/V*W\", (p_tokens+d_tokens), llm.hidden_size, llm.sub_dmodel * (llm.num_q_heads+llm.num_kv_heads*2), 1)\n",
    "\n",
    "    # decode token attention\n",
    "    wl.add_layer(KVCache, \"dKVCache_Read\", d_context_length, llm.sub_dmodel, 2*llm.num_kv_heads, d_tokens)\n",
    "    wl.add_layer(Va_Mqa, \"dQ*gK\", 1, llm.hidden_size, llm.sub_dmodel * llm.num_kv_heads, d_tokens, qrouped_q=llm.grouped_q)\n",
    "    wl.add_layer(Va_Mqa, \"dQ*gK*gV\", 1, llm.hidden_size, llm.sub_dmodel * llm.num_kv_heads, d_tokens, qrouped_q=llm.grouped_q)\n",
    "\n",
    "    # prefill token attention\n",
    "    wl.add_layer(Async_KVCache, \"pKVCache_Read\", p_context_length, llm.sub_dmodel, 2*llm.num_kv_heads, 1)\n",
    "    wl.add_layer(Ma_Mqa, \"pQ*gK\", p_tokens, llm.hidden_size, p_context_length, 1, qrouped_q=llm.grouped_q)\n",
    "    wl.add_layer(Ma_Mqa, \"pQ*gK*gV\", p_tokens, llm.hidden_size, p_context_length, 1, qrouped_q=llm.grouped_q)\n",
    "    wl.add_layer(Async_KVCache, \"KVCache_Store\", p_tokens, llm.sub_dmodel, 2*llm.num_kv_heads, 1)\n",
    "\n",
    "    wl.add_layer(Ma_Mw, \"O*W\", (p_tokens+d_tokens), llm.hidden_size, llm.hidden_size, 1)\n",
    "    wl.add_layer(Ma_Mw, \"FFN_up\", (p_tokens+d_tokens), llm.hidden_size, llm.intermediate_size, 1)\n",
    "    wl.add_layer(Ma_Mw, \"FFN_gate\", (p_tokens+d_tokens), llm.hidden_size, llm.intermediate_size, 1)\n",
    "    wl.add_layer(Ma_Mw, \"FFN_down\", (p_tokens+d_tokens), llm.intermediate_size, llm.hidden_size, 1)\n",
    "\n",
    "    # Sum up the compute and memory usage\n",
    "    wl.total_compute = sum(item[0] for item in wl.compute)\n",
    "    wl.total_weight = sum(item[0] for item in wl.weight)\n",
    "    wl.total_kv_cache = sum(item[0] for item in wl.kv_cache)\n",
    "\n",
    "    if DEBUG_PRINT:\n",
    "        print(\"Chunked Compute\", wl.total_compute)\n",
    "        print(\"Chunked Weights\", wl.total_weight)\n",
    "        print(\"Chunked KV cache\", wl.total_kv_cache)\n",
    "        print_list(\"Chunked Compute\", wl.compute)\n",
    "        print_list(\"Chunked Weights\", wl.weight)\n",
    "        print_list(\"Chunked KV cache\", wl.kv_cache)\n",
    "\n",
    "    # Print detailed information if the flag is set\n",
    "    if DETAIL_PRINT:\n",
    "        print(\"\")\n",
    "        print(\"   Details:\")\n",
    "        print(\"   === Input parameters ===\")\n",
    "        print(\"   Prefill context length:\", p_context_length)\n",
    "        print(\"   Decode context length:\", d_context_length)\n",
    "        print(\"   Bytes per FP value:\", bytes_per_value) # To-Do: this is set globally, not specific to the model or workload (P2)\n",
    "        print(\"   Layers:\", llm.num_hidden_layers)\n",
    "\n",
    "        print(\"   Total Compute (MACs):\", convert_number_to_string(wl.total_compute * llm.num_hidden_layers))\n",
    "        print(\"   Total Weights Footprint (Bytes):\", convert_number_to_string(wl.total_weight * llm.num_hidden_layers))\n",
    "        print(\"   Total KV Cache Footprint (Bytes):\", convert_number_to_string(wl.total_kv_cache * llm.num_hidden_layers))\n",
    "\n",
    "    return wl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050367e0",
   "metadata": {},
   "source": [
    "Kernel breakdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71b3428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first tuple in token_lengths\n",
    "\n",
    "if 0:\n",
    "#for token_length in token_lengths:\n",
    "    # Unpack the tuple into two variables\n",
    "    input_length, output_length = token_length\n",
    "    print(\"Input length:\", input_length)\n",
    "    print(\"Output length:\", output_length)\n",
    "    p_batch_size = 1\n",
    "    d_batch_size = 256\n",
    "    chunksize = 256\n",
    "\n",
    "    # Perform prefill\n",
    "    perform_prefill(llm, input_length, p_batch_size)\n",
    "    # Perform decode\n",
    "    perform_decode(llm, input_length, d_batch_size)    \n",
    "    # Perform chunked prefill\n",
    "    d_tokens = chunksize * output_length // (input_length + output_length)\n",
    "    p_tokens = chunksize - d_tokens\n",
    "    d_context_length = input_length + output_length // 2    # This is used to approximately the average decode computation\n",
    "    p_context_length = int(input_length / 1.73 - p_tokens//2)             # 1.73 = sqrt(3) This is used to approximately the average prefill computation\n",
    "\n",
    "    perform_chunkedprefill(llm, p_context_length, p_tokens, d_context_length, d_tokens)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd388892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#### Calculate time per kernels \n",
    "# Realistic tiling (P3)\n",
    "\n",
    "# Simple roofline: If matrix-matrix operations, assume compute bound.  If matrix-vector operations, assume memory bound.\n",
    "# Assume wl is a WorkloadProfile instance (from perform_prefill, perform_decode, or perform_chunkedprefill)\n",
    "# HW_SPEC should define MACs_per_second, Bandwidth, and Frequency\n",
    "def estimate_kernel_times(wl, HW_SPEC):\n",
    "    kernel_times = []\n",
    "    for layer in wl.layers:\n",
    "        layer_type = layer[\"type\"]\n",
    "        name = layer[\"name\"]\n",
    "        args = layer[\"args\"]\n",
    "\n",
    "        # Matrix-matrix operations (compute bound)\n",
    "        if layer_type in [Ma_Mw, Ma_Mqa, Mw_Ma, Ma_Ma]:\n",
    "            # Find the corresponding compute entry\n",
    "            compute_entry = next((c for c in wl.compute if c[1] == name), None)\n",
    "            if compute_entry:\n",
    "                compute = compute_entry[0]\n",
    "                exec_cycle = compute / HW_SPEC[\"MACs_per_second\"] * HW_SPEC[\"Frequency\"]\n",
    "                bound = \"Compute\"\n",
    "            else:\n",
    "                exec_cycle = None\n",
    "                bound = \"N/A\"\n",
    "        # Matrix-vector operations (memory bound)\n",
    "        elif layer_type in [Va_Mw, Va_Mqa, Vw_Va, Va_Va]:\n",
    "            # Find the corresponding weight entry\n",
    "            weight_entry = next((w for w in wl.weight if w[1] == name), None)\n",
    "            if weight_entry:\n",
    "                memory = weight_entry[0] * bytes_per_value\n",
    "                exec_cycle = memory / HW_SPEC[\"Bandwidth\"] * HW_SPEC[\"Frequency\"]\n",
    "                bound = \"Memory\"\n",
    "            else:\n",
    "                exec_cycle = None\n",
    "                bound = \"N/A\"\n",
    "        elif layer_type == KVCache:\n",
    "            # Find the corresponding weight entry\n",
    "            cache_entry = next((w for w in wl.kv_cache if w[1] == name), None)\n",
    "            if cache_entry:\n",
    "                memory = cache_entry[0] * bytes_per_value\n",
    "                exec_cycle = memory / HW_SPEC[\"Bandwidth\"] * HW_SPEC[\"Frequency\"]\n",
    "                bound = \"Memory\"\n",
    "            else:\n",
    "                exec_cycle = None\n",
    "                bound = \"N/A\"\n",
    "        elif layer_type == Async_KVCache:\n",
    "            exec_cycle = None\n",
    "            bound = None\n",
    "        else:\n",
    "            exec_cycle = None\n",
    "            bound = \"Unknown\"\n",
    "\n",
    "        kernel_times.append({\n",
    "            \"name\": name,\n",
    "            \"type\": layer_type,\n",
    "            \"bound\": bound,\n",
    "            \"exec_time in cycles\": exec_cycle,\n",
    "        })\n",
    "\n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"   Layer: {name}, Type: {layer_type}, Bound: {bound}, Exec Time: {exec_cycle:.0f} cycles\" if exec_cycle is not None else f\"      Layer: {name}, Type: {layer_type}, Bound: {bound}, Exec Time: N/A\")\n",
    "\n",
    "    return kernel_times\n",
    "\n",
    "import math\n",
    "\n",
    "def estimate_tiling_sizes(cache_size, bytes_per_value, num_fixed_dims, *dims):\n",
    "    \"\"\"\n",
    "    Estimate tiling sizes for matrix multiplication given cache_size, bytes_per_value, and some fixed dimensions.\n",
    "    If num_fixed_dims > 0, dims should provide the fixed dimensions in order (dim_1, dim_2, dim_3).\n",
    "    The remaining dimensions will be estimated to fit the cache.\n",
    "\n",
    "    Args:\n",
    "        cache_size: total cache size available (e.g., L3 cache)\n",
    "        bytes_per_value: bytes per matrix element\n",
    "        num_fixed_dims: number of fixed dimensions provided (0-2)\n",
    "        *dims: the fixed dimension values (dim_m, dim_k, dim_n) in order\n",
    "\n",
    "    Returns:\n",
    "        tuple: (dim_m, dim_k, dim_n) estimated tile sizes\n",
    "    \"\"\"\n",
    "    match num_fixed_dims:\n",
    "        case 0:\n",
    "            # Assume cache is split equally among the three matrices\n",
    "            size_per_matrix = cache_size / 3\n",
    "            # For cubic root, use **(1/3)\n",
    "            perfect_dim = (size_per_matrix / bytes_per_value) ** (1/2)\n",
    "            return perfect_dim\n",
    "        case 1:\n",
    "            # Solve for x in: x * x + 2 * fixed_dim * x < cache_size / bytes_per_value\n",
    "            # Rearranged: x^2 + 2 * fixed_dim * x - (cache_size / bytes_per_value) < 0\n",
    "            # Use quadratic formula: x = (-b + sqrt(b^2 - 4ac)) / 2a, where a=1, b=2*fixed_dim, c=-(cache_size / bytes_per_value)\n",
    "            b = dims[0]*2\n",
    "            discriminant = b**2 + 4 * (cache_size / bytes_per_value)\n",
    "            dim_2 = (-b + math.sqrt(discriminant)) / 2\n",
    "            return dim_2\n",
    "        case 2:\n",
    "            # Because the third dimension is not fixed, we can use the remaining cache space\n",
    "            # to estimate the third dimension\n",
    "            remaining_capacity = (cache_size - (dims[0] * dims[1] * bytes_per_value))\n",
    "            dim_3 = remaining_capacity / (bytes_per_value * (dims[0]+dims[1]))\n",
    "            return dim_3\n",
    "        \n",
    "# Simple roofline: If matrix-matrix operations, assume compute bound.  If matrix-vector operations, assume memory bound.\n",
    "# Assume wl is a WorkloadProfile instance (from perform_prefill, perform_decode, or perform_chunkedprefill)\n",
    "# HW_SPEC should define MACs_per_second, L3_cache_capacity, Bandwidth, and Frequency\n",
    "def estimate_kernel_times_by_theoretical_tiler(wl, HW_SPEC):\n",
    "\n",
    "    # Theoretical tiling: the best tiling used all the cache space for matrix A, matrix B, and matrix C\n",
    "    \n",
    "    kernel_times = []\n",
    "    for layer in wl.layers:\n",
    "        layer_type = layer[\"type\"]\n",
    "        name = layer[\"name\"]\n",
    "        args = layer[\"args\"]\n",
    "\n",
    "        # Matrix-matrix operations or weight is associated in the layer type\n",
    "        if \"M\" in layer_type or \"w\" in layer_type:\n",
    "            # Find the corresponding compute entry\n",
    "            compute_entry = next((c for c in wl.compute if c[1] == name), None)\n",
    "\n",
    "            if compute_entry:\n",
    "                # Unpack dimensions from args\n",
    "                # Unpack dimensions from compute_entry if available, else fallback to args\n",
    "                # compute_entry = (compute, name, dim_m, dim_k, dim_n, batch_size)\n",
    "                L3_cache_capacity = HW_SPEC[\"L3_cache_capacity\"]\n",
    "                wldims = [compute_entry[2], compute_entry[3], compute_entry[4]]\n",
    "                batch_size = compute_entry[5]\n",
    "\n",
    "                # Step 0: use batch size to adjust dimensions so that the output matrix is as closer to square as possible\n",
    "                if batch_size > 1:\n",
    "                    # Adjust dimensions based on batch size to maximize cache reuse\n",
    "                    if wldims[0] > wldims[2] and wldims[0] / wldims[2] > batch_size:\n",
    "                        wldims[2] = wldims[2] * batch_size\n",
    "                    elif wldims[2] > wldims[0] and wldims[2] / wldims[0] > batch_size:\n",
    "                        wldims[0] = wldims[0] * batch_size\n",
    "                    else:\n",
    "                        ratio = wldims[0] / wldims[2]\n",
    "                        batch_size = batch_size / ratio\n",
    "                        wldims[2] = wldims[0] = wldims[0] * ((batch_size) ** (1/2))\n",
    "\n",
    "                # Step 1: find the tiling dims when all 3 dims are flexible\n",
    "                t_dim = estimate_tiling_sizes(L3_cache_capacity, bytes_per_value, 0)\n",
    "                dims = [(0, wldims[0]), (1, wldims[1]), (2, wldims[2])]                \n",
    "                dims_sorted = sorted(dims, key=lambda x: x[1])\n",
    "                if dims_sorted[0][1] >= t_dim:\n",
    "                    tile_dims = [(0, t_dim), (1, t_dim), (2, t_dim)]\n",
    "                else: # Step 2: find the tiling dims when 1 dim (the smallest) is fixed\n",
    "                    t_dim = estimate_tiling_sizes(L3_cache_capacity, bytes_per_value, 1, dims_sorted[0][1])\n",
    "                    if dims_sorted[1][1] >= t_dim:\n",
    "                        dims_sorted[1] = (dims_sorted[1][0], t_dim)\n",
    "                        dims_sorted[2] = (dims_sorted[2][0], t_dim)\n",
    "                        tile_dims = sorted(dims_sorted, key=lambda x: x[0])\n",
    "                    else: # Step 3: find the last tiling dim when the smallest 2 dims are fixed\n",
    "                        t_dim = estimate_tiling_sizes(L3_cache_capacity, bytes_per_value, 2, dims_sorted[0][1], dims_sorted[1][1])\n",
    "                        if dims_sorted[2][1] >= t_dim:\n",
    "                            dims_sorted[2] = (dims_sorted[2][0], t_dim) # fix the last dim due to the capacity limit\n",
    "                            tile_dims = sorted(dims_sorted, key=lambda x: x[0])\n",
    "                        else:\n",
    "                            tile_dims = sorted(dims_sorted, key=lambda x: x[0])\n",
    "                \n",
    "                print(f\"   WL_dims: {wldims[0]}x{wldims[1]}x{wldims[2]}, Best tiler: {tile_dims[0][1]:.1f}x{tile_dims[1][1]:.1f}x{tile_dims[2][1]:.1f}\")\n",
    "                compute = tile_dims[0][1] * tile_dims[1][1] * tile_dims[2][1]\n",
    "                cmp_cycle = compute / HW_SPEC[\"MACs_per_second\"] * HW_SPEC[\"Frequency\"]\n",
    "                memory = (tile_dims[0][1] * tile_dims[1][1] + tile_dims[2][1] * tile_dims[1][1]) * bytes_per_value\n",
    "                mem_cycle = memory / HW_SPEC[\"Bandwidth\"] * HW_SPEC[\"Frequency\"]\n",
    "\n",
    "                # Step 4: compare the cmp_cycle and the mem_cycle and decide the bound\n",
    "                print(f\"   cmp_cycle: {cmp_cycle*compute_entry[0]/compute:0.1f}, mem_cycle: {mem_cycle*compute_entry[0]/compute:0.1f}, mem_cycle-to-cmp_cycle: {(mem_cycle/cmp_cycle):0.1f}\")\n",
    "                if cmp_cycle > mem_cycle:\n",
    "                    exec_cycle = cmp_cycle*compute_entry[0]/compute\n",
    "                    bound = \"Compute\"\n",
    "                else:\n",
    "                    exec_cycle = mem_cycle*compute_entry[0]/compute\n",
    "                    bound = \"Memory\"\n",
    "            else:\n",
    "                exec_cycle = None\n",
    "                bound = \"N/A\"\n",
    "        elif layer_type == KVCache:\n",
    "            # Find the corresponding weight entry\n",
    "            cache_entry = next((w for w in wl.kv_cache if w[1] == name), None)\n",
    "            if cache_entry:\n",
    "                memory = cache_entry[0] * bytes_per_value\n",
    "                exec_cycle = memory / HW_SPEC[\"Bandwidth\"] * HW_SPEC[\"Frequency\"]\n",
    "                bound = \"Memory\"\n",
    "            else:\n",
    "                exec_cycle = None\n",
    "                bound = \"N/A\"\n",
    "        elif layer_type == Async_KVCache:\n",
    "            exec_cycle = None\n",
    "            bound = None\n",
    "        else:\n",
    "            print (f\"Unhandled layer type: {layer_type}\")\n",
    "            exec_cycle = None\n",
    "            bound = \"Unknown\"\n",
    "\n",
    "        kernel_times.append({\n",
    "            \"name\": name,\n",
    "            \"type\": layer_type,\n",
    "            \"bound\": bound,\n",
    "            \"exec_time in cycles\": exec_cycle,\n",
    "        })\n",
    "\n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"   Layer: {name}, Type: {layer_type}, Bound: {bound}, Exec Time: {exec_cycle:.0f} cycles\" if exec_cycle is not None else f\"      Layer: {name}, Type: {layer_type}, Bound: {bound}, Exec Time: N/A\")\n",
    "\n",
    "    return kernel_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15452045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefill Compute 231928233984\n",
      "Prefill Weights 218103808\n",
      "Prefill KV cache 2097152\n",
      "\t== Prefill Compute ==\n",
      "\t [25769803776, 'Q/K/V*W', 1024, 4096, 6144, 1]\n",
      "\t [4294967296, 'Q*gK', 1024, 4096, 1024, 1]\n",
      "\t [4294967296, 'Q*gK*gV', 1024, 4096, 1024, 1]\n",
      "\t [17179869184, 'O*W', 1024, 4096, 4096, 1]\n",
      "\t [60129542144, 'FFN_up', 1024, 4096, 14336, 1]\n",
      "\t [60129542144, 'FFN_gate', 1024, 4096, 14336, 1]\n",
      "\t [60129542144, 'FFN_down', 1024, 14336, 4096, 1]\n",
      "\t== Prefill Weights ==\n",
      "\t [25165824, 'Q/K/V*W', 4096, 6144]\n",
      "\t [16777216, 'O*W', 4096, 4096]\n",
      "\t [58720256, 'FFN_up', 4096, 14336]\n",
      "\t [58720256, 'FFN_gate', 4096, 14336]\n",
      "\t [58720256, 'FFN_down', 14336, 4096]\n",
      "\t== Prefill KV cache ==\n",
      "\t [2097152, 'KVCache_Store', 1024, 2048, 1]\n",
      "\n",
      "   Details:\n",
      "   === Input parameters ===\n",
      "   Context length: 1024\n",
      "   Bytes per FP value: 2\n",
      "   Layers: 32\n",
      "   Total Compute (MACs): 6.8T\n",
      "   Total Weights Footprint (Bytes): 6.5G\n",
      "   Total KV Cache Footprint (Bytes): 64.0M\n",
      "   WL_dims: 1024x4096x6144, Best tiler: 1024.0x3439.5x3439.5\n",
      "   cmp_cycle: 786432.0, mem_cycle: 533600.6, mem_cycle-to-cmp_cycle: 0.7\n",
      "   Layer: Q/K/V*W, Type: Ma_Mw, Bound: Compute, Exec Time: 786432 cycles\n",
      "   WL_dims: 1024x4096x1024, Best tiler: 1024.0x4096.0x1024.0\n",
      "   cmp_cycle: 131072.0, mem_cycle: 137061.4, mem_cycle-to-cmp_cycle: 1.0\n",
      "   Layer: Q*gK, Type: Ma_Mqa, Bound: Memory, Exec Time: 137061 cycles\n",
      "   WL_dims: 1024x4096x1024, Best tiler: 1024.0x4096.0x1024.0\n",
      "   cmp_cycle: 131072.0, mem_cycle: 137061.4, mem_cycle-to-cmp_cycle: 1.0\n",
      "   Layer: Q*gK*gV, Type: Ma_Mqa, Bound: Memory, Exec Time: 137061 cycles\n",
      "   WL_dims: 1024x4096x4096, Best tiler: 1024.0x3439.5x3439.5\n",
      "   cmp_cycle: 524288.0, mem_cycle: 355733.7, mem_cycle-to-cmp_cycle: 0.7\n",
      "   Layer: O*W, Type: Ma_Mw, Bound: Compute, Exec Time: 524288 cycles\n",
      "   WL_dims: 1024x4096x14336, Best tiler: 1024.0x3439.5x3439.5\n",
      "   cmp_cycle: 1835008.0, mem_cycle: 1245068.0, mem_cycle-to-cmp_cycle: 0.7\n",
      "   Layer: FFN_up, Type: Ma_Mw, Bound: Compute, Exec Time: 1835008 cycles\n",
      "   WL_dims: 1024x4096x14336, Best tiler: 1024.0x3439.5x3439.5\n",
      "   cmp_cycle: 1835008.0, mem_cycle: 1245068.0, mem_cycle-to-cmp_cycle: 0.7\n",
      "   Layer: FFN_gate, Type: Ma_Mw, Bound: Compute, Exec Time: 1835008 cycles\n",
      "   WL_dims: 1024x14336x4096, Best tiler: 1024.0x3439.5x3439.5\n",
      "   cmp_cycle: 1835008.0, mem_cycle: 1245068.0, mem_cycle-to-cmp_cycle: 0.7\n",
      "   Layer: FFN_down, Type: Ma_Mw, Bound: Compute, Exec Time: 1835008 cycles\n",
      "      Layer: KVCache_Store, Type: Async_KVCache, Bound: None, Exec Time: N/A\n",
      "Total compute-bound cycles: 6815744\n",
      "Total memory-bound cycles: 274123\n"
     ]
    }
   ],
   "source": [
    "#### Output \n",
    "# Estimated execution time for different kernels (P2)\n",
    "# Estimated activities for different kernels for power analysis (P6)\n",
    "\n",
    "# Breakdown between different kernels and the shape of the tensors: Mw_Ma, Ma_Ma, Mw_Va, Vw_Va, Va_Va\n",
    "input_length = 1024\n",
    "output_length = 512\n",
    "p_batch_size = 1\n",
    "d_batch_size = 256\n",
    "chunksize = 256\n",
    "d_tokens = chunksize * output_length // (input_length + output_length)\n",
    "p_tokens = chunksize - d_tokens\n",
    "d_context_length = input_length + output_length // 2    # This is used to approximately the average decode computation\n",
    "p_context_length = int(input_length / 1.73 - p_tokens//2)             # 1.73 = sqrt(3) This is used to approximately the average prefill computation\n",
    "\n",
    "wl = perform_prefill(llm, input_length, p_batch_size)\n",
    "#wl = perform_decode(llm, input_length, d_batch_size)    \n",
    "#wl = perform_chunkedprefill(llm, p_context_length, p_tokens, d_context_length, d_tokens)    \n",
    "kernel_times = estimate_kernel_times_by_theoretical_tiler(wl, HW_SPEC)\n",
    "\n",
    "compute_cycles = sum(k[\"exec_time in cycles\"] for k in kernel_times if k[\"bound\"] == \"Compute\" and k[\"exec_time in cycles\"] is not None)\n",
    "memory_cycles = sum(k[\"exec_time in cycles\"] for k in kernel_times if k[\"bound\"] == \"Memory\" and k[\"exec_time in cycles\"] is not None)\n",
    "\n",
    "print(f\"Total compute-bound cycles: {compute_cycles:.0f}\")\n",
    "print(f\"Total memory-bound cycles: {memory_cycles:.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
